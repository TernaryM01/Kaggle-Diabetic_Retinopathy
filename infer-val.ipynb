{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad5e57d6",
   "metadata": {},
   "source": [
    "## Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c482ac85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauribuntu/miniconda3/envs/causal-dl-torch/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/mauribuntu/miniconda3/envs/causal-dl-torch/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/mauribuntu/miniconda3/envs/causal-dl-torch/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1b4cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetV2OrdinalClassifier(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"efficientnetv2_rw_m\", lr=1e-4, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Use timm to load pretrained backbone, remove classifier head\n",
    "        self.net = timm.create_model(\n",
    "            self.hparams.model_name,\n",
    "            pretrained=True,\n",
    "            num_classes=0,  # remove original head\n",
    "            \n",
    "            drop_rate=0.3,\n",
    "            drop_path_rate=0.3\n",
    "        )\n",
    "\n",
    "        in_features = self.net.num_features\n",
    "        self.head = nn.Linear(in_features, self.num_classes - 1)  # 4 outputs for 5 ordinal classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.net(x)\n",
    "        logits = self.head(features)\n",
    "        return logits\n",
    "    \n",
    "    def predict_class(self, logits):\n",
    "        probas = logits.sigmoid()\n",
    "        return (probas > 0.5).sum(dim=1)\n",
    "    \n",
    "    def ordinal_targets(self, labels):\n",
    "        \"\"\"\n",
    "        Converts integer class labels (0 to num_classes - 1) into ordinal binary targets.\n",
    "        For example, label 2 becomes [1, 1, 0, 0] for num_classes = 5\n",
    "        \"\"\"\n",
    "        batch_size = labels.size(0)\n",
    "        num_thresholds = self.num_classes - 1  # one less than number of classes\n",
    "        labels_expanded = labels.unsqueeze(1)  # Expand labels to shape (batch_size, 1)\n",
    "        # Create comparison thresholds: shape (1, num_thresholds) = [0, 1, 2, 3]\n",
    "        thresholds = torch.arange(num_thresholds, device=labels.device).unsqueeze(0)\n",
    "        # Compare each label to thresholds: True where label > threshold\n",
    "        binary_targets = labels_expanded > thresholds  # shape (batch_size, num_thresholds)\n",
    "        return binary_targets.float()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        targets = self.ordinal_targets(labels)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "        \n",
    "        preds = (logits.sigmoid() > 0.5).sum(dim=1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc',  acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        targets = self.ordinal_targets(labels)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "\n",
    "        preds = (logits.sigmoid() > 0.5).sum(dim=1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc',  acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=5e-5)\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',              # we're watching val_loss (lower is better)\n",
    "                factor=0.5,              # reduce LR by this factor\n",
    "                patience=5,              # after N epochs of no improvement\n",
    "                min_lr=1e-6,             # don’t go below this\n",
    "                verbose=True\n",
    "            ),\n",
    "            'monitor': 'val_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7801d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacentLabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, smoothing: float = 0.1, num_classes: int = 5, window_size: int = 1):\n",
    "        \"\"\"\n",
    "        Exponential-decay label smoothing for ordinal targets.\n",
    "\n",
    "        Args:\n",
    "          smoothing: total probability mass to smooth away from the true class (0 <= s < 1).\n",
    "          num_classes: total number of ordinal classes.\n",
    "          window_size: how many steps to consider on each side of the true class.\n",
    "                       (1 for adjacent only, 2 to include distance-2 neighbors, etc.)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert 0 <= smoothing < 1, \"smoothing must be in [0,1).\"\n",
    "        self.smoothing = smoothing\n",
    "        self.num_classes = num_classes\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # Precompute smoothing distributions for each possible true class 0..num_classes-1\n",
    "        # according to your two requirements:\n",
    "        #   1) exp decay by distance\n",
    "        #   2) center weight = 1 - smoothing\n",
    "        R = smoothing / (1.0 - smoothing)  # ratio of total neighbor mass to center mass\n",
    "\n",
    "        weight_matrix = []\n",
    "        for t in range(num_classes):\n",
    "            # how many valid steps on each side\n",
    "            left_n  = min(window_size,             t)\n",
    "            right_n = min(window_size, num_classes - 1 - t)\n",
    "\n",
    "            # Solve for decay d so that sum(d^1..d^left_n) + sum(d^1..d^right_n) = R\n",
    "            # Newton's method on f(d) = sum_{k=1..L} d^k + sum_{k=1..R} d^k - R = 0\n",
    "            if left_n + right_n == 0:\n",
    "                d = 0.0\n",
    "            else:\n",
    "                # initial guess\n",
    "                d = R / (left_n + right_n)\n",
    "                for _ in range(50):\n",
    "                    # f(d) and f'(d)\n",
    "                    f = sum(d**k for k in range(1, left_n+1)) + sum(d**k for k in range(1, right_n+1)) - R\n",
    "                    fp = sum(k * d**(k-1) for k in range(1, left_n+1)) + sum(k * d**(k-1) for k in range(1, right_n+1))\n",
    "                    d = max(d - f/(fp + 1e-12), 1e-12)\n",
    "\n",
    "            # Build raw (unnormalized) weights for this true class t\n",
    "            raw = torch.zeros(num_classes, dtype=torch.float64)\n",
    "            for c in range(num_classes):\n",
    "                dist = abs(c - t)\n",
    "                if dist == 0:\n",
    "                    raw[c] = 1.0\n",
    "                elif dist <= window_size:\n",
    "                    raw[c] = d**dist\n",
    "                # else remains 0\n",
    "\n",
    "            # Normalize so sum(raw) = 1 and center weight = 1 - smoothing\n",
    "            raw = raw / raw.sum()\n",
    "            weight_matrix.append(raw.float())\n",
    "\n",
    "        # Stack into [num_classes, num_classes] tensor\n",
    "        weight_matrix = torch.stack(weight_matrix, dim=0)  # weight_matrix[t] is the distribution for true class t\n",
    "        self.register_buffer('weight_matrix', weight_matrix)\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        logits: (B, C)\n",
    "        target: (B,) integer tensor in [0..C-1]\n",
    "        \"\"\"\n",
    "        # Get the precomputed soft-target distributions\n",
    "        # shape → (B, C)\n",
    "        true_dist = self.weight_matrix[target]\n",
    "\n",
    "        # Standard cross-entropy with log-softmax\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        loss = -(true_dist * log_probs).sum(dim=-1).mean()\n",
    "        return loss\n",
    "    \n",
    "    def debug_dist(self, true_class: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the smoothed distribution for a given true class.\n",
    "\n",
    "        Args:\n",
    "            true_class: int, between 0 and num_classes - 1.\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape (num_classes,) showing the target distribution.\n",
    "        \"\"\"\n",
    "        if not (0 <= true_class < self.num_classes):\n",
    "            raise ValueError(f\"true_class must be between 0 and {self.num_classes - 1}, got {true_class}.\")\n",
    "        \n",
    "        dist = self.weight_matrix[true_class]\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b3442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXtClassifier(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"convnext_small.fb_in22k_ft_in1k_384\", lr=1e-4, num_classes=5, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # create & swap in a new head\n",
    "        self.net = timm.create_model(\n",
    "            self.hparams.model_name,\n",
    "            pretrained=True,\n",
    "            num_classes=self.hparams.num_classes,\n",
    "            \n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2,\n",
    "        )\n",
    "        \n",
    "        self.criterion = AdjacentLabelSmoothingLoss(\n",
    "            smoothing=self.hparams.smoothing,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def predict_class(self, logits):\n",
    "        return logits.argmax(dim=-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        acc  = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc',  acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        acc  = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('val_acc',  acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=1e-5)\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',              # we're watching val_loss (lower is better)\n",
    "                factor=0.5,              # reduce LR by this factor\n",
    "                patience=5,              # after N epochs of no improvement\n",
    "                min_lr=1e-6,             # don’t go below this\n",
    "                verbose=True\n",
    "            ),\n",
    "            'monitor': 'val_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e8fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetV2Classifier(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"efficientnetv2_rw_m\", lr=1e-4, num_classes=5, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # create & swap in a new head\n",
    "        self.net = timm.create_model(\n",
    "            self.hparams.model_name,\n",
    "            pretrained=True,\n",
    "            num_classes=self.hparams.num_classes,\n",
    "            \n",
    "            drop_rate=0.4,        # 🔥 add stronger dropout (applied before final FC)\n",
    "            drop_path_rate=0.3,   # 🔥 stochastic depth (helps regularize deep nets)\n",
    "        )\n",
    "        \n",
    "        self.criterion = AdjacentLabelSmoothingLoss(\n",
    "            smoothing=self.hparams.smoothing,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def predict_class(self, logits):\n",
    "        return logits.argmax(dim=-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        acc  = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc',  acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        acc  = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc',  acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=1e-4)\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',              # we're watching val_loss (lower is better)\n",
    "                factor=0.5,              # reduce LR by this factor\n",
    "                patience=5,              # after N epochs of no improvement\n",
    "                min_lr=1e-6,             # don’t go below this\n",
    "                verbose=True\n",
    "            ),\n",
    "            'monitor': 'val_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd501fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Classifier(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"resnet50.a1_in1k\", lr=1e-4, num_classes=5,\n",
    "                 smoothing=0.1, window_size=1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # create & swap in a new head\n",
    "        self.net = timm.create_model(\n",
    "            self.hparams.model_name,\n",
    "            pretrained=True,\n",
    "            num_classes=self.hparams.num_classes,\n",
    "            \n",
    "            drop_rate=0.3,        # 🔥 add stronger dropout (applied before final FC)\n",
    "            # drop_path_rate=0.3,   # 🔥 stochastic depth (helps regularize deep nets)\n",
    "        )\n",
    "        \n",
    "        self.criterion = AdjacentLabelSmoothingLoss(\n",
    "            smoothing=self.hparams.smoothing,\n",
    "            window_size=self.hparams.window_size,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def predict_class(self, logits):\n",
    "        return logits.argmax(dim=-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        \n",
    "        preds = logits.argmax(dim=-1)\n",
    "        acc  = (preds == labels).float().mean()\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc',  acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        acc  = (preds == labels).float().mean()\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('val_acc',  acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=1e-4)\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',              # we're watching val_loss (lower is better)\n",
    "                factor=0.5,              # reduce LR by this factor\n",
    "                patience=5,              # after N epochs of no improvement\n",
    "                min_lr=1e-6,             # don’t go below this\n",
    "                verbose=True\n",
    "            ),\n",
    "            'monitor': 'val_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80ec5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXtRegressor(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"convnext_small.fb_in22k_ft_in1k_384\", lr=1e-4, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=True,    # We will manually load weights later\n",
    "            num_classes=1,        # One output neuron for regression\n",
    "            \n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)  # Output shape [batch_size]\n",
    "    \n",
    "    def predict_class(self, outputs):\n",
    "        return outputs.round().clamp(0, self.hparams.num_classes - 1).long()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self(imgs)\n",
    "        loss = F.mse_loss(preds, labels.float())\n",
    "\n",
    "        preds_rounded = preds.round().clamp(0, self.hparams.num_classes - 1)\n",
    "        acc = (preds_rounded == labels).float().mean()\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc',  acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self(imgs)\n",
    "        loss = F.mse_loss(preds, labels.float())\n",
    "\n",
    "        preds_rounded = preds.round().clamp(0, self.hparams.num_classes - 1)\n",
    "        acc = (preds_rounded == labels).float().mean()\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc',  acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=1e-5)\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',          # still minimizing val_loss (MSE)\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-6,\n",
    "                verbose=True\n",
    "            ),\n",
    "            'monitor': 'val_loss',   # watch val_loss (MSE) to reduce LR\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_classifier_ckpt(cls, path, model_name=\"convnext_small.fb_in22k_ft_in1k_384\",\n",
    "                                  lr=1e-4, num_classes=5):\n",
    "        \"\"\"\n",
    "        Create a ConvNeXtRegressor and load weights from a classification checkpoint.\n",
    "        \"\"\"\n",
    "        model = cls(model_name=model_name, lr=lr)\n",
    "        checkpoint = torch.load(path, map_location='cpu')\n",
    "\n",
    "        state_dict = checkpoint['state_dict']\n",
    "\n",
    "        # Remove classification head weights (they don't match)\n",
    "        filtered_state_dict = {k: v for k, v in state_dict.items() if 'head' not in k}\n",
    "        model.load_state_dict(filtered_state_dict, strict=False)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4cfefd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Regressor(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"resnet50.a1_in1k\", lr=1e-4, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=True,    # We will manually load weights later\n",
    "            num_classes=1,        # One output neuron for regression\n",
    "            \n",
    "            drop_rate=0.3,\n",
    "            # drop_path_rate=0.2,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)  # Output shape [batch_size]\n",
    "    \n",
    "    def predict_class(self, outputs):\n",
    "        return outputs.round().clamp(0, self.hparams.num_classes - 1).long()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self(imgs)\n",
    "        loss = F.mse_loss(preds, labels.float())\n",
    "\n",
    "        preds_rounded = preds.round().clamp(0, self.hparams.num_classes - 1)\n",
    "        acc = (preds_rounded == labels).float().mean()\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc',  acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self(imgs)\n",
    "        loss = F.mse_loss(preds, labels.float())\n",
    "\n",
    "        preds_rounded = preds.round().clamp(0, self.hparams.num_classes - 1)\n",
    "        acc = (preds_rounded == labels).float().mean()\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc',  acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=1e-4)\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',          # still minimizing val_loss (MSE)\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-6,\n",
    "                verbose=True\n",
    "            ),\n",
    "            'monitor': 'val_loss',   # watch val_loss (MSE) to reduce LR\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_classifier_ckpt(cls, path, model_name=\"convnext_small.fb_in22k_ft_in1k_384\",\n",
    "                                  lr=1e-4, num_classes=5):\n",
    "        \"\"\"\n",
    "        Create a ConvNeXtRegressor and load weights from a classification checkpoint.\n",
    "        \"\"\"\n",
    "        model = cls(model_name=model_name, lr=lr)\n",
    "        checkpoint = torch.load(path, map_location='cpu')\n",
    "\n",
    "        state_dict = checkpoint['state_dict']\n",
    "\n",
    "        # Remove classification head weights (they don't match)\n",
    "        filtered_state_dict = {k: v for k, v in state_dict.items() if 'fc' not in k}\n",
    "        model.load_state_dict(filtered_state_dict, strict=False)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf48f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {\n",
    "#     'convnext':   ('checkpoints/convnext-small-dropout-l2reg-augs-adjsmooth-full-refined-epoch=00-val_loss=0.6888-val_acc=0.8396.ckpt',\n",
    "#                    ConvNeXtClassifier),\n",
    "#     'convnext-r': ('checkpoints/convnext-small-reg-dropout-l2reg-augs-full-epoch=23-val_loss=0.2984-val_acc=0.8075.ckpt',\n",
    "#                    ConvNeXtRegressor),\n",
    "#     'effnet':     ('checkpoints/effnet-v2rw-m-dropout-l2reg-augs-adjsmooth-full-epoch=14-val_loss=0.7004-val_acc=0.8305.ckpt',\n",
    "#                    EfficientNetV2Classifier),\n",
    "#     'effnet-p':   ('checkpoints/effnet-v2rw-m-dropout-l2reg-augs-adjsmooth-epoch=12-val_loss=0.6849-val_acc=0.8370.ckpt',\n",
    "#                    EfficientNetV2Classifier),\n",
    "#     'effnet-o':   ('checkpoints/effnet-v2rw-m-ordinal-dropout2-l2reg2-augs-full-epoch=22-val_loss=0.1580-val_acc=0.8278.ckpt',\n",
    "#                    EfficientNetV2OrdinalClassifier),\n",
    "#     'resnet':     ('checkpoints/resnet-50-dropout-l2reg2-augs-adjsmooth2-full-epoch=39-val_loss=0.8696-val_acc=0.8299.ckpt',\n",
    "#                    ResNet50Classifier),\n",
    "#     'resnet-n':   ('checkpoints/resnet-50-dropout-l2reg-augs-adjsmooth-full-refined-epoch=00-val_loss=0.7068-val_acc=0.8268.ckpt',\n",
    "#                    ResNet50Classifier),\n",
    "#     'resnet-r':   ('checkpoints/resnet-50-reg-dropout-l2reg-augs-full-epoch=26-val_loss=0.3978-val_acc=0.7151.ckpt',\n",
    "#                    ResNet50Regressor),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244c2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {\n",
    "#     'convnext':   ('checkpoints/convnext-small-sv768-dropout-l2reg-augs-adjsmooth-part1-epoch=26-val_loss=0.6054-val_acc=0.8661.ckpt',\n",
    "#                    ConvNeXtClassifier),\n",
    "#     'convnext-r': ('checkpoints/convnext-small-reg-sv768-dropout-l2reg-augs-part1-epoch=13-val_loss=0.1747-val_acc=0.8462.ckpt',\n",
    "#                    ConvNeXtRegressor),\n",
    "#     'effnet':     ('checkpoints/effnet-v2rw-m-sv768-dropout-l2reg-augs-adjsmooth-part1-epoch=48-val_loss=0.6221-val_acc=0.8590.ckpt',\n",
    "#                    EfficientNetV2Classifier),\n",
    "#     # 'effnet-p':   ('checkpoints/effnet-v2rw-m-dropout-l2reg-augs-adjsmooth-epoch=12-val_loss=0.6849-val_acc=0.8370.ckpt',\n",
    "#     #                EfficientNetV2Classifier),\n",
    "#     'effnet-o':   ('checkpoints/effnet-v2rw-m-ordinal-sv768-dropout-l2reg-augs-part1-epoch=06-val_loss=0.1286-val_acc=0.8319.ckpt',\n",
    "#                    EfficientNetV2OrdinalClassifier),\n",
    "#     'resnet':     ('checkpoints/resnet-50-sv768-dropout-l2reg-augs-adjsmooth2-part1-epoch=31-val_loss=0.8662-val_acc=0.8590.ckpt',\n",
    "#                    ResNet50Classifier),\n",
    "#     'resnet-n':   ('checkpoints/resnet-50-sv768-dropout-l2reg-augs-adjsmooth-part1-epoch=22-val_loss=0.6740-val_acc=0.8547.ckpt',\n",
    "#                    ResNet50Classifier),\n",
    "#     # 'resnet-r':   ('checkpoints/resnet-50-reg-dropout-l2reg-augs-full-epoch=26-val_loss=0.3978-val_acc=0.7151.ckpt',\n",
    "#     #                ResNet50Regressor),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e762e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {\n",
    "#     'convnext':   ('checkpoints/convnext-small-sv768-dropout-l2reg-augs-adjsmooth-part2-epoch=45-val_loss=0.6401-val_acc=0.8507.ckpt',\n",
    "#                    ConvNeXtClassifier),\n",
    "#     'convnext-r': ('checkpoints/convnext-small-reg-dropout-l2reg-augs-full-epoch=23-val_loss=0.2984-val_acc=0.8075.ckpt',\n",
    "#                    ConvNeXtRegressor),\n",
    "#     'effnet':     ('checkpoints/effnet-v2rw-m-sv768-dropout-l2reg-augs-adjsmooth-part2-epoch=46-val_loss=0.6480-val_acc=0.8508.ckpt',\n",
    "#                    EfficientNetV2Classifier),\n",
    "#     'effnet-p':   ('checkpoints/effnet-v2rw-m-dropout-l2reg-augs-adjsmooth-epoch=12-val_loss=0.6849-val_acc=0.8370.ckpt',\n",
    "#                    EfficientNetV2Classifier),\n",
    "#     'effnet-o':   ('checkpoints/effnet-v2rw-m-ordinal-dropout2-l2reg2-augs-full-epoch=22-val_loss=0.1580-val_acc=0.8278.ckpt',\n",
    "#                    EfficientNetV2OrdinalClassifier),\n",
    "#     'resnet':     ('checkpoints/resnet-50-sv768-dropout-l2reg-augs-adjsmooth-part2-epoch=33-val_loss=0.8686-val_acc=0.8346.ckpt',\n",
    "#                    ResNet50Classifier),\n",
    "#     # 'resnet-n':   ('checkpoints/resnet-50-sv768-dropout-l2reg-augs-adjsmooth-part1-epoch=22-val_loss=0.6740-val_acc=0.8547.ckpt',\n",
    "#     #                ResNet50Classifier),\n",
    "#     'resnet-r':   ('checkpoints/resnet-50-reg-dropout-l2reg-augs-full-epoch=26-val_loss=0.3978-val_acc=0.7151.ckpt',\n",
    "#                    ResNet50Regressor),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ef85ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # 'convnext':   ('checkpoints/convnext-small-sv768-dropout-l2reg-augs-adjsmooth-part2-epoch=45-val_loss=0.6401-val_acc=0.8507.ckpt',\n",
    "    # 'convnext':   ('checkpoints/convnext-small-sv728dyn-rand_shrink-dropout-l2reg-augs-adjsmooth-train2-refine1-epoch=20-val_loss=0.6240-val_acc=0.8580.ckpt',\n",
    "    'convnext':   ('checkpoints/convnext-small-st448-sv768dyn-rand_shrink-dropout-l2reg-augs2-adjsmooth-train2-refine1-epoch=14-val_loss=0.6224-val_acc=0.8635.ckpt',\n",
    "                   ConvNeXtClassifier),\n",
    "    # 'convnext-r': ('checkpoints/convnext-small-reg-dropout-l2reg-augs-full-epoch=23-val_loss=0.2984-val_acc=0.8075.ckpt',\n",
    "    #                ConvNeXtRegressor),\n",
    "    # 'effnet':     ('checkpoints/effnet-v2rw-m-sv768-dropout-l2reg-augs-adjsmooth-part2-epoch=46-val_loss=0.6480-val_acc=0.8508.ckpt',\n",
    "    # 'effnet':     ('checkpoints/effnet-v2rw-m-sv728dyn-rand_shrink-dropout-l2reg-augs-adjsmooth-train2-refine1-epoch=15-val_loss=0.6569-val_acc=0.8460.ckpt',\n",
    "    'effnet':     ('checkpoints/effnet-v2rw-m-st408-sv768dyn-rand_shrink-dropout-l2reg-augs2-adjsmooth-train2-refine1-epoch=15-val_loss=0.6679-val_acc=0.8454.ckpt',\n",
    "                   EfficientNetV2Classifier),\n",
    "    # 'effnet-p':   ('checkpoints/effnet-v2rw-m-dropout-l2reg-augs-adjsmooth-epoch=12-val_loss=0.6849-val_acc=0.8370.ckpt',\n",
    "    #                EfficientNetV2Classifier),\n",
    "    # 'effnet-o':   ('checkpoints/effnet-v2rw-m-ordinal-dropout2-l2reg2-augs-full-epoch=22-val_loss=0.1580-val_acc=0.8278.ckpt',\n",
    "    #                EfficientNetV2OrdinalClassifier),\n",
    "    # 'resnet':     ('checkpoints/resnet-50-sv768-dropout-l2reg-augs-adjsmooth-part2-epoch=33-val_loss=0.8686-val_acc=0.8346.ckpt',\n",
    "    # 'resnet':     ('checkpoints/resnet-50-sv728dyn-rand_shrink-dropout-l2reg-augs-adjsmooth-train2-refine1-epoch=23-val_loss=0.9103-val_acc=0.8230.ckpt',\n",
    "    'resnet':     ('checkpoints/resnet-50-st477-sv768dyn-rand_shrink-dropout-l2reg-augs2-adjsmooth-train2-refine1-epoch=24-val_loss=0.8834-val_acc=0.8389.ckpt',\n",
    "                   ResNet50Classifier),\n",
    "    # 'resnet-n':   ('checkpoints/resnet-50-sv768-dropout-l2reg-augs-adjsmooth-part1-epoch=22-val_loss=0.6740-val_acc=0.8547.ckpt',\n",
    "    #                ResNet50Classifier),\n",
    "    # 'resnet-r':   ('checkpoints/resnet-50-reg-dropout-l2reg-augs-full-epoch=26-val_loss=0.3978-val_acc=0.7151.ckpt',\n",
    "    #                ResNet50Regressor),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017a53e",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fc393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df_train = pd.read_csv('df_train.csv')\n",
    "# df_val = pd.read_csv('df_val.csv')\n",
    "\n",
    "# df_train1 = df_train[df_train['img_dir'].str.contains('aptos')]\n",
    "# df_val1 = df_val[df_val['img_dir'].str.contains('aptos')]\n",
    "# df_trainval1 = pd.concat([df_train1, df_val1], ignore_index=True)\n",
    "\n",
    "# # df_train2 = df_train[df_train['img_dir'].str.contains('diabetic-retinopathy-detection')]\n",
    "# # df_val2 = df_val[df_val['img_dir'].str.contains('diabetic-retinopathy-detection')]\n",
    "# # df_trainval2 = pd.concat([df_train2, df_val2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "637f360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df_train = pd.read_csv('df_train1_new.csv')\n",
    "df_val1_new = pd.read_csv('df_val1_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df44709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # id = row['id']\n",
    "        label = int(row['label'])\n",
    "        img_dir = row['img_dir']\n",
    "\n",
    "        image = Image.open(img_dir).convert('RGB')  # ensure 3 channels\n",
    "\n",
    "        if self.transform:\n",
    "            image = np.array(image)\n",
    "            image = self.transform(image=image)['image']\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9873ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauribuntu/miniconda3/envs/causal-dl-torch/lib/python3.12/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.6' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# IMAGE_SIZE_VAL = 480\n",
    "IMAGE_SIZE_VAL = 768\n",
    "# IMAGE_SIZE_VAL = 512\n",
    "# IMAGE_SIZE_VAL = 728\n",
    "\n",
    "def downscale(img, **kwargs):\n",
    "    h, w = img.shape[:2]\n",
    "    if max(h, w) > IMAGE_SIZE_VAL:\n",
    "        img = A.LongestMaxSize(max_size=IMAGE_SIZE_VAL, p=1.0)(image=img)[\"image\"]\n",
    "    return img\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Lambda(name=\"Downscale\", image=downscale),\n",
    "    # A.Resize(IMAGE_SIZE_TRAIN, IMAGE_SIZE_TRAIN),\n",
    "\n",
    "    A.PadIfNeeded(IMAGE_SIZE_VAL, IMAGE_SIZE_VAL, fill=0),\n",
    "\n",
    "    A.Normalize(  # For model pretrained on ImageNet\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8289c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE_VAL = 10\n",
    "# val_dataset = TrainDataset(df_trainval1, val_transform)\n",
    "val_dataset = TrainDataset(df_val1_new, val_transform)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE_VAL, shuffle=False, num_workers=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b66c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assume that val_dataloader does NOT shuffle, so order matches df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8be983c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing convnext…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cce1c73adc34427b7db9e0763a4e9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convnext\n",
      "Validation QWK = 0.92631\n",
      "Validation Accuracy = 0.86346\n",
      "Processing effnet…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae7ebe882c24399bd138edf1ef085f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "effnet\n",
      "Validation QWK = 0.89776\n",
      "Validation Accuracy = 0.84544\n",
      "Processing resnet…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73561becbf4249f0bc92c4a01d02667b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet\n",
      "Validation QWK = 0.90183\n",
      "Validation Accuracy = 0.83889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "\n",
    "# Prepare an empty DataFrame\n",
    "df_stack21 = pd.DataFrame()\n",
    "\n",
    "# Loop each model\n",
    "for model_name, (ckpt_path, model_class) in models.items():\n",
    "    print(f'Processing {model_name}…')\n",
    "\n",
    "    # 1) load & move to device\n",
    "    model = model_class.load_from_checkpoint(ckpt_path, strict=False)\n",
    "    model = model.to(device).eval()\n",
    "\n",
    "    # 2) collect raw outputs in a list\n",
    "    all_preds_raw = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(val_dataloader):\n",
    "            imgs = imgs.to(device)\n",
    "            with torch.amp.autocast(device.type):\n",
    "                preds_raw = model(imgs)\n",
    "            preds = model.predict_class(preds_raw)\n",
    "            \n",
    "            all_preds_raw.append(preds_raw.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    # 3) concatenate and convert to numpy\n",
    "    all_preds_raw = torch.cat(all_preds_raw, dim=0).numpy()  # shape (N,) or (N, D)\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    # 4) turn into stacking columns\n",
    "    if all_preds_raw.ndim == 1:\n",
    "        # regressor → one column\n",
    "        df_stack21[f'{model_name}_pred'] = all_preds_raw\n",
    "    else:\n",
    "        # multi‐dim output → one column per dim\n",
    "        D = all_preds_raw.shape[1]\n",
    "        for i in range(D):\n",
    "            df_stack21[f'{model_name}_{i}'] = all_preds_raw[:, i]\n",
    "\n",
    "    # cleanup\n",
    "    del model\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    qwk = cohen_kappa_score(all_labels, all_preds, weights='quadratic')\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    print(model_name)\n",
    "    print(f'Validation QWK = {qwk:.5f}')\n",
    "    print(f'Validation Accuracy = {acc:.5f}')\n",
    "\n",
    "# finally, append the true label column (order must match val_dataloader)\n",
    "# df_stack21['label'] = df_trainval1['label'].values\n",
    "df_stack21['label'] = df_val1_new['label'].values\n",
    "\n",
    "# df_stack2['group'] = df_val2['img_dir'].str.slice(start=47).str.split('_').str[0]\n",
    "\n",
    "# df_stack21.to_csv('df_stack21.csv', index=False)\n",
    "df_stack21.to_csv('df_stack_train2_dyn1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df63fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-dl-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
