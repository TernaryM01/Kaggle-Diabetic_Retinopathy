{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3377edea",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edea1942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "test_imgs_dir1 = Path('aptos2019-blindness-detection/test_images/processed')\n",
    "# test_imgs_dir2 = Path('diabetic-retinopathy-detection/test/processed')\n",
    "\n",
    "imgs_list1 = [p for p in test_imgs_dir1.glob(\"*.png\") if p.is_file()]\n",
    "# imgs_list2 = [p for p in test_imgs_dir2.glob(\"*.jpeg\") if p.is_file()]\n",
    "# imgs_list = imgs_list1 + imgs_list2\n",
    "\n",
    "# Create DataFrame\n",
    "# df_test = pd.DataFrame({'img_dir': imgs_list})\n",
    "df_test = pd.DataFrame({'img_dir': imgs_list1})\n",
    "# df_test.to_csv('df_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b17e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('df_test1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3f9f52",
   "metadata": {},
   "source": [
    "==========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac3cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_test = pd.read_csv('df_test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ffe52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauribuntu/miniconda3/envs/causal-dl-torch/lib/python3.12/site-packages/albumentations/check_version.py:107: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "  data = fetch_version_info()\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def downscale(img, **kwargs):\n",
    "    h, w = img.shape[:2]\n",
    "    if max(h, w) > IMAGE_SIZE_VAL:\n",
    "        img = A.LongestMaxSize(max_size=IMAGE_SIZE_VAL, p=1.0)(image=img)[\"image\"]\n",
    "    return img\n",
    "\n",
    "# IMAGE_SIZE_TRAIN = 352\n",
    "# IMAGE_SIZE_VAL = 480\n",
    "IMAGE_SIZE_VAL = 768\n",
    "# IMAGE_SIZE_VAL = 512\n",
    "\n",
    "# train_transform = A.Compose(...)\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Lambda(name=\"Downscale\", image=downscale),\n",
    "    # A.Resize(IMAGE_SIZE_TRAIN, IMAGE_SIZE_TRAIN),\n",
    "\n",
    "    A.PadIfNeeded(IMAGE_SIZE_VAL, IMAGE_SIZE_VAL, fill=0),\n",
    "\n",
    "    A.Normalize(  # For model pretrained on ImageNet\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3881e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # id = row['id']\n",
    "        # label = int(row['label'])\n",
    "        img_dir = row['img_dir']\n",
    "\n",
    "        image = Image.open(img_dir).convert('RGB')  # ensure 3 channels\n",
    "\n",
    "        if self.transform:\n",
    "            image = np.array(image)\n",
    "            image = self.transform(image=image)['image']\n",
    "\n",
    "        return image#, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59b33b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# BATCH_SIZE_TRAIN = ...\n",
    "BATCH_SIZE_VAL = 12\n",
    "\n",
    "# train_dataset = TrainDataset(df_train, train_transform)\n",
    "test_dataset = TestDataset(df_test, val_transform)\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, num_workers=10)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE_VAL, shuffle=False, num_workers=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab58c6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauribuntu/miniconda3/envs/causal-dl-torch/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/mauribuntu/miniconda3/envs/causal-dl-torch/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/mauribuntu/miniconda3/envs/causal-dl-torch/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7710b34",
   "metadata": {},
   "source": [
    "## Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "466fccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetV2OrdinalClassifier(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"efficientnetv2_rw_m\", lr=1e-4, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Use timm to load pretrained backbone, remove classifier head\n",
    "        self.net = timm.create_model(\n",
    "            self.hparams.model_name,\n",
    "            pretrained=True,\n",
    "            num_classes=0,  # remove original head\n",
    "            \n",
    "            drop_rate=0.3,\n",
    "            drop_path_rate=0.3\n",
    "        )\n",
    "\n",
    "        in_features = self.net.num_features\n",
    "        self.head = nn.Linear(in_features, self.num_classes - 1)  # 4 outputs for 5 ordinal classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.net(x)\n",
    "        logits = self.head(features)\n",
    "        return logits\n",
    "    \n",
    "    def predict_class(self, logits):\n",
    "        probas = logits.sigmoid()\n",
    "        return (probas > 0.5).sum(dim=1)\n",
    "    \n",
    "    def ordinal_targets(self, labels):\n",
    "        \"\"\"\n",
    "        Converts integer class labels (0 to num_classes - 1) into ordinal binary targets.\n",
    "        For example, label 2 becomes [1, 1, 0, 0] for num_classes = 5\n",
    "        \"\"\"\n",
    "        batch_size = labels.size(0)\n",
    "        num_thresholds = self.num_classes - 1  # one less than number of classes\n",
    "        labels_expanded = labels.unsqueeze(1)  # Expand labels to shape (batch_size, 1)\n",
    "        # Create comparison thresholds: shape (1, num_thresholds) = [0, 1, 2, 3]\n",
    "        thresholds = torch.arange(num_thresholds, device=labels.device).unsqueeze(0)\n",
    "        # Compare each label to thresholds: True where label > threshold\n",
    "        binary_targets = labels_expanded > thresholds  # shape (batch_size, num_thresholds)\n",
    "        return binary_targets.float()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        targets = self.ordinal_targets(labels)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "        \n",
    "        preds = (logits.sigmoid() > 0.5).sum(dim=1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc',  acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        targets = self.ordinal_targets(labels)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "\n",
    "        preds = (logits.sigmoid() > 0.5).sum(dim=1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc',  acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=5e-5)\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',              # we're watching val_loss (lower is better)\n",
    "                factor=0.5,              # reduce LR by this factor\n",
    "                patience=5,              # after N epochs of no improvement\n",
    "                min_lr=1e-6,             # donâ€™t go below this\n",
    "                verbose=True\n",
    "            ),\n",
    "            'monitor': 'val_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4c32fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacentLabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, smoothing: float = 0.1, num_classes: int = 5, window_size: int = 1):\n",
    "        \"\"\"\n",
    "        Exponential-decay label smoothing for ordinal targets.\n",
    "\n",
    "        Args:\n",
    "          smoothing: total probability mass to smooth away from the true class (0 <= s < 1).\n",
    "          num_classes: total number of ordinal classes.\n",
    "          window_size: how many steps to consider on each side of the true class.\n",
    "                       (1 for adjacent only, 2 to include distance-2 neighbors, etc.)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert 0 <= smoothing < 1, \"smoothing must be in [0,1).\"\n",
    "        self.smoothing = smoothing\n",
    "        self.num_classes = num_classes\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # Precompute smoothing distributions for each possible true class 0..num_classes-1\n",
    "        # according to your two requirements:\n",
    "        #   1) exp decay by distance\n",
    "        #   2) center weight = 1 - smoothing\n",
    "        R = smoothing / (1.0 - smoothing)  # ratio of total neighbor mass to center mass\n",
    "\n",
    "        weight_matrix = []\n",
    "        for t in range(num_classes):\n",
    "            # how many valid steps on each side\n",
    "            left_n  = min(window_size,             t)\n",
    "            right_n = min(window_size, num_classes - 1 - t)\n",
    "\n",
    "            # Solve for decay d so that sum(d^1..d^left_n) + sum(d^1..d^right_n) = R\n",
    "            # Newton's method on f(d) = sum_{k=1..L} d^k + sum_{k=1..R} d^k - R = 0\n",
    "            if left_n + right_n == 0:\n",
    "                d = 0.0\n",
    "            else:\n",
    "                # initial guess\n",
    "                d = R / (left_n + right_n)\n",
    "                for _ in range(50):\n",
    "                    # f(d) and f'(d)\n",
    "                    f = sum(d**k for k in range(1, left_n+1)) + sum(d**k for k in range(1, right_n+1)) - R\n",
    "                    fp = sum(k * d**(k-1) for k in range(1, left_n+1)) + sum(k * d**(k-1) for k in range(1, right_n+1))\n",
    "                    d = max(d - f/(fp + 1e-12), 1e-12)\n",
    "\n",
    "            # Build raw (unnormalized) weights for this true class t\n",
    "            raw = torch.zeros(num_classes, dtype=torch.float64)\n",
    "            for c in range(num_classes):\n",
    "                dist = abs(c - t)\n",
    "                if dist == 0:\n",
    "                    raw[c] = 1.0\n",
    "                elif dist <= window_size:\n",
    "                    raw[c] = d**dist\n",
    "                # else remains 0\n",
    "\n",
    "            # Normalize so sum(raw) = 1 and center weight = 1 - smoothing\n",
    "            raw = raw / raw.sum()\n",
    "            weight_matrix.append(raw.float())\n",
    "\n",
    "        # Stack into [num_classes, num_classes] tensor\n",
    "        weight_matrix = torch.stack(weight_matrix, dim=0)  # weight_matrix[t] is the distribution for true class t\n",
    "        self.register_buffer('weight_matrix', weight_matrix)\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        logits: (B, C)\n",
    "        target: (B,) integer tensor in [0..C-1]\n",
    "        \"\"\"\n",
    "        # Get the precomputed soft-target distributions\n",
    "        # shape â†’ (B, C)\n",
    "        true_dist = self.weight_matrix[target]\n",
    "\n",
    "        # Standard cross-entropy with log-softmax\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        loss = -(true_dist * log_probs).sum(dim=-1).mean()\n",
    "        return loss\n",
    "    \n",
    "    def debug_dist(self, true_class: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the smoothed distribution for a given true class.\n",
    "\n",
    "        Args:\n",
    "            true_class: int, between 0 and num_classes - 1.\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape (num_classes,) showing the target distribution.\n",
    "        \"\"\"\n",
    "        if not (0 <= true_class < self.num_classes):\n",
    "            raise ValueError(f\"true_class must be between 0 and {self.num_classes - 1}, got {true_class}.\")\n",
    "        \n",
    "        dist = self.weight_matrix[true_class]\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eac537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXtClassifier(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"convnext_small.fb_in22k_ft_in1k_384\", lr=1e-4, num_classes=5, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # create & swap in a new head\n",
    "        self.net = timm.create_model(\n",
    "            self.hparams.model_name,\n",
    "            pretrained=True,\n",
    "            num_classes=self.hparams.num_classes,\n",
    "            \n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2,\n",
    "        )\n",
    "        \n",
    "        self.criterion = AdjacentLabelSmoothingLoss(\n",
    "            smoothing=self.hparams.smoothing,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def predict_class(self, logits):\n",
    "        return logits.argmax(dim=-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        acc  = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc',  acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        acc  = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('val_acc',  acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=1e-5)\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',              # we're watching val_loss (lower is better)\n",
    "                factor=0.5,              # reduce LR by this factor\n",
    "                patience=5,              # after N epochs of no improvement\n",
    "                min_lr=1e-6,             # donâ€™t go below this\n",
    "                verbose=True\n",
    "            ),\n",
    "            'monitor': 'val_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d087574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetV2Classifier(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"efficientnetv2_rw_m\", lr=1e-4, num_classes=5, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # create & swap in a new head\n",
    "        self.net = timm.create_model(\n",
    "            self.hparams.model_name,\n",
    "            pretrained=True,\n",
    "            num_classes=self.hparams.num_classes,\n",
    "            \n",
    "            drop_rate=0.4,        # ðŸ”¥ add stronger dropout (applied before final FC)\n",
    "            drop_path_rate=0.3,   # ðŸ”¥ stochastic depth (helps regularize deep nets)\n",
    "        )\n",
    "        \n",
    "        self.criterion = AdjacentLabelSmoothingLoss(\n",
    "            smoothing=self.hparams.smoothing,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def predict_class(self, logits):\n",
    "        return logits.argmax(dim=-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        acc  = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc',  acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        acc  = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc',  acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=1e-4)\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',              # we're watching val_loss (lower is better)\n",
    "                factor=0.5,              # reduce LR by this factor\n",
    "                patience=5,              # after N epochs of no improvement\n",
    "                min_lr=1e-6,             # donâ€™t go below this\n",
    "                verbose=True\n",
    "            ),\n",
    "            'monitor': 'val_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cc1e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Classifier(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"resnet50.a1_in1k\", lr=1e-4, num_classes=5,\n",
    "                 smoothing=0.1, window_size=1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # create & swap in a new head\n",
    "        self.net = timm.create_model(\n",
    "            self.hparams.model_name,\n",
    "            pretrained=True,\n",
    "            num_classes=self.hparams.num_classes,\n",
    "            \n",
    "            drop_rate=0.3,        # ðŸ”¥ add stronger dropout (applied before final FC)\n",
    "            # drop_path_rate=0.3,   # ðŸ”¥ stochastic depth (helps regularize deep nets)\n",
    "        )\n",
    "        \n",
    "        self.criterion = AdjacentLabelSmoothingLoss(\n",
    "            smoothing=self.hparams.smoothing,\n",
    "            window_size=self.hparams.window_size,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def predict_class(self, logits):\n",
    "        return logits.argmax(dim=-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        \n",
    "        preds = logits.argmax(dim=-1)\n",
    "        acc  = (preds == labels).float().mean()\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc',  acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        logits = self(imgs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        acc  = (preds == labels).float().mean()\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        self.log('val_acc',  acc, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=1e-4)\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',              # we're watching val_loss (lower is better)\n",
    "                factor=0.5,              # reduce LR by this factor\n",
    "                patience=5,              # after N epochs of no improvement\n",
    "                min_lr=1e-6,             # donâ€™t go below this\n",
    "                verbose=True\n",
    "            ),\n",
    "            'monitor': 'val_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f52a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXtRegressor(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"convnext_small.fb_in22k_ft_in1k_384\", lr=1e-4, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=True,    # We will manually load weights later\n",
    "            num_classes=1,        # One output neuron for regression\n",
    "            \n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)  # Output shape [batch_size]\n",
    "    \n",
    "    def predict_class(self, outputs):\n",
    "        return outputs.round().clamp(0, self.hparams.num_classes - 1).long()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self(imgs)\n",
    "        loss = F.mse_loss(preds, labels.float())\n",
    "\n",
    "        preds_rounded = preds.round().clamp(0, self.hparams.num_classes - 1)\n",
    "        acc = (preds_rounded == labels).float().mean()\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc',  acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self(imgs)\n",
    "        loss = F.mse_loss(preds, labels.float())\n",
    "\n",
    "        preds_rounded = preds.round().clamp(0, self.hparams.num_classes - 1)\n",
    "        acc = (preds_rounded == labels).float().mean()\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc',  acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=1e-5)\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',          # still minimizing val_loss (MSE)\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-6,\n",
    "                verbose=True\n",
    "            ),\n",
    "            'monitor': 'val_loss',   # watch val_loss (MSE) to reduce LR\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_classifier_ckpt(cls, path, model_name=\"convnext_small.fb_in22k_ft_in1k_384\",\n",
    "                                  lr=1e-4, num_classes=5):\n",
    "        \"\"\"\n",
    "        Create a ConvNeXtRegressor and load weights from a classification checkpoint.\n",
    "        \"\"\"\n",
    "        model = cls(model_name=model_name, lr=lr)\n",
    "        checkpoint = torch.load(path, map_location='cpu')\n",
    "\n",
    "        state_dict = checkpoint['state_dict']\n",
    "\n",
    "        # Remove classification head weights (they don't match)\n",
    "        filtered_state_dict = {k: v for k, v in state_dict.items() if 'head' not in k}\n",
    "        model.load_state_dict(filtered_state_dict, strict=False)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "971d3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Regressor(pl.LightningModule):\n",
    "    def __init__(self, model_name=\"resnet50.a1_in1k\", lr=1e-4, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=True,    # We will manually load weights later\n",
    "            num_classes=1,        # One output neuron for regression\n",
    "            \n",
    "            drop_rate=0.3,\n",
    "            # drop_path_rate=0.2,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)  # Output shape [batch_size]\n",
    "    \n",
    "    def predict_class(self, outputs):\n",
    "        return outputs.round().clamp(0, self.hparams.num_classes - 1).long()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self(imgs)\n",
    "        loss = F.mse_loss(preds, labels.float())\n",
    "\n",
    "        preds_rounded = preds.round().clamp(0, self.hparams.num_classes - 1)\n",
    "        acc = (preds_rounded == labels).float().mean()\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc',  acc, prog_bar=True, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self(imgs)\n",
    "        loss = F.mse_loss(preds, labels.float())\n",
    "\n",
    "        preds_rounded = preds.round().clamp(0, self.hparams.num_classes - 1)\n",
    "        acc = (preds_rounded == labels).float().mean()\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc',  acc, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=1e-4)\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',          # still minimizing val_loss (MSE)\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-6,\n",
    "                verbose=True\n",
    "            ),\n",
    "            'monitor': 'val_loss',   # watch val_loss (MSE) to reduce LR\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_classifier_ckpt(cls, path, model_name=\"convnext_small.fb_in22k_ft_in1k_384\",\n",
    "                                  lr=1e-4, num_classes=5):\n",
    "        \"\"\"\n",
    "        Create a ConvNeXtRegressor and load weights from a classification checkpoint.\n",
    "        \"\"\"\n",
    "        model = cls(model_name=model_name, lr=lr)\n",
    "        checkpoint = torch.load(path, map_location='cpu')\n",
    "\n",
    "        state_dict = checkpoint['state_dict']\n",
    "\n",
    "        # Remove classification head weights (they don't match)\n",
    "        filtered_state_dict = {k: v for k, v in state_dict.items() if 'fc' not in k}\n",
    "        model.load_state_dict(filtered_state_dict, strict=False)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3800a2de",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9434a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {\n",
    "#     'convnext':   ('checkpoints/convnext-small-dropout-l2reg-augs-adjsmooth-full-refined-epoch=00-val_loss=0.6888-val_acc=0.8396.ckpt',\n",
    "#                    ConvNeXtClassifier),\n",
    "#     'convnext-r': ('checkpoints/convnext-small-reg-dropout-l2reg-augs-full-epoch=23-val_loss=0.2984-val_acc=0.8075.ckpt',\n",
    "#                    ConvNeXtRegressor),\n",
    "#     'effnet':     ('checkpoints/effnet-v2rw-m-dropout-l2reg-augs-adjsmooth-full-epoch=14-val_loss=0.7004-val_acc=0.8305.ckpt',\n",
    "#                    EfficientNetV2Classifier),\n",
    "#     'effnet-p':   ('checkpoints/effnet-v2rw-m-dropout-l2reg-augs-adjsmooth-epoch=12-val_loss=0.6849-val_acc=0.8370.ckpt',\n",
    "#                    EfficientNetV2Classifier),\n",
    "#     'effnet-o':   ('checkpoints/effnet-v2rw-m-ordinal-dropout2-l2reg2-augs-full-epoch=22-val_loss=0.1580-val_acc=0.8278.ckpt',\n",
    "#                    EfficientNetV2OrdinalClassifier),\n",
    "#     'resnet':     ('checkpoints/resnet-50-dropout-l2reg2-augs-adjsmooth2-full-epoch=39-val_loss=0.8696-val_acc=0.8299.ckpt',\n",
    "#                    ResNet50Classifier),\n",
    "#     'resnet-n':   ('checkpoints/resnet-50-dropout-l2reg-augs-adjsmooth-full-refined-epoch=00-val_loss=0.7068-val_acc=0.8268.ckpt',\n",
    "#                    ResNet50Classifier),\n",
    "#     'resnet-r':   ('checkpoints/resnet-50-reg-dropout-l2reg-augs-full-epoch=26-val_loss=0.3978-val_acc=0.7151.ckpt',\n",
    "#                    ResNet50Regressor),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {\n",
    "#     'convnext':   ('checkpoints/convnext-small-sv768-dropout-l2reg-augs-adjsmooth-part1-epoch=26-val_loss=0.6054-val_acc=0.8661.ckpt',\n",
    "#                    ConvNeXtClassifier),\n",
    "#     'convnext-r': ('checkpoints/convnext-small-reg-sv768-dropout-l2reg-augs-part1-epoch=13-val_loss=0.1747-val_acc=0.8462.ckpt',\n",
    "#                    ConvNeXtRegressor),\n",
    "#     'effnet':     ('checkpoints/effnet-v2rw-m-sv768-dropout-l2reg-augs-adjsmooth-part1-epoch=48-val_loss=0.6221-val_acc=0.8590.ckpt',\n",
    "#                    EfficientNetV2Classifier),\n",
    "#     # 'effnet-p':   ('checkpoints/effnet-v2rw-m-dropout-l2reg-augs-adjsmooth-epoch=12-val_loss=0.6849-val_acc=0.8370.ckpt',\n",
    "#     #                EfficientNetV2Classifier),\n",
    "#     'effnet-o':   ('checkpoints/effnet-v2rw-m-ordinal-sv768-dropout-l2reg-augs-part1-epoch=06-val_loss=0.1286-val_acc=0.8319.ckpt',\n",
    "#                    EfficientNetV2OrdinalClassifier),\n",
    "#     'resnet':     ('checkpoints/resnet-50-sv768-dropout-l2reg-augs-adjsmooth2-part1-epoch=31-val_loss=0.8662-val_acc=0.8590.ckpt',\n",
    "#                    ResNet50Classifier),\n",
    "#     'resnet-n':   ('checkpoints/resnet-50-sv768-dropout-l2reg-augs-adjsmooth-part1-epoch=22-val_loss=0.6740-val_acc=0.8547.ckpt',\n",
    "#                    ResNet50Classifier),\n",
    "#     # 'resnet-r':   ('checkpoints/resnet-50-reg-dropout-l2reg-augs-full-epoch=26-val_loss=0.3978-val_acc=0.7151.ckpt',\n",
    "#     #                ResNet50Regressor),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6cb63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {\n",
    "#     'convnext':   ('checkpoints/convnext-small-sv768-dropout-l2reg-augs-adjsmooth-part2-epoch=45-val_loss=0.6401-val_acc=0.8507.ckpt',\n",
    "#                    ConvNeXtClassifier),\n",
    "#     'convnext-r': ('checkpoints/convnext-small-reg-dropout-l2reg-augs-full-epoch=23-val_loss=0.2984-val_acc=0.8075.ckpt',\n",
    "#                    ConvNeXtRegressor),\n",
    "#     'effnet':     ('checkpoints/effnet-v2rw-m-sv768-dropout-l2reg-augs-adjsmooth-part2-epoch=46-val_loss=0.6480-val_acc=0.8508.ckpt',\n",
    "#                    EfficientNetV2Classifier),\n",
    "#     'effnet-p':   ('checkpoints/effnet-v2rw-m-dropout-l2reg-augs-adjsmooth-epoch=12-val_loss=0.6849-val_acc=0.8370.ckpt',\n",
    "#                    EfficientNetV2Classifier),\n",
    "#     'effnet-o':   ('checkpoints/effnet-v2rw-m-ordinal-dropout2-l2reg2-augs-full-epoch=22-val_loss=0.1580-val_acc=0.8278.ckpt',\n",
    "#                    EfficientNetV2OrdinalClassifier),\n",
    "#     'resnet':     ('checkpoints/resnet-50-sv768-dropout-l2reg-augs-adjsmooth-part2-epoch=33-val_loss=0.8686-val_acc=0.8346.ckpt',\n",
    "#                    ResNet50Classifier),\n",
    "#     # 'resnet-n':   ('checkpoints/resnet-50-sv768-dropout-l2reg-augs-adjsmooth-part1-epoch=22-val_loss=0.6740-val_acc=0.8547.ckpt',\n",
    "#     #                ResNet50Classifier),\n",
    "#     'resnet-r':   ('checkpoints/resnet-50-reg-dropout-l2reg-augs-full-epoch=26-val_loss=0.3978-val_acc=0.7151.ckpt',\n",
    "#                    ResNet50Regressor),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94faf95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # 'convnext':   ('checkpoints/convnext-small-sv768-dropout-l2reg-augs-adjsmooth-part2-epoch=45-val_loss=0.6401-val_acc=0.8507.ckpt',\n",
    "    # 'convnext':   ('checkpoints/convnext-small-sv728dyn-rand_shrink-dropout-l2reg-augs-adjsmooth-train2-refine1-epoch=20-val_loss=0.6240-val_acc=0.8580.ckpt',\n",
    "    'convnext':   ('checkpoints/convnext-small-st448-sv768dyn-rand_shrink-dropout-l2reg-augs2-adjsmooth-train2-refine1-epoch=14-val_loss=0.6224-val_acc=0.8635.ckpt',\n",
    "                   ConvNeXtClassifier),\n",
    "    # 'convnext-r': ('checkpoints/convnext-small-reg-dropout-l2reg-augs-full-epoch=23-val_loss=0.2984-val_acc=0.8075.ckpt',\n",
    "    #                ConvNeXtRegressor),\n",
    "    # 'effnet':     ('checkpoints/effnet-v2rw-m-sv768-dropout-l2reg-augs-adjsmooth-part2-epoch=46-val_loss=0.6480-val_acc=0.8508.ckpt',\n",
    "    # 'effnet':     ('checkpoints/effnet-v2rw-m-sv728dyn-rand_shrink-dropout-l2reg-augs-adjsmooth-train2-refine1-epoch=15-val_loss=0.6569-val_acc=0.8460.ckpt',\n",
    "    'effnet':     ('checkpoints/effnet-v2rw-m-st408-sv768dyn-rand_shrink-dropout-l2reg-augs2-adjsmooth-train2-refine1-epoch=15-val_loss=0.6679-val_acc=0.8454.ckpt',\n",
    "                   EfficientNetV2Classifier),\n",
    "    # 'effnet-p':   ('checkpoints/effnet-v2rw-m-dropout-l2reg-augs-adjsmooth-epoch=12-val_loss=0.6849-val_acc=0.8370.ckpt',\n",
    "    #                EfficientNetV2Classifier),\n",
    "    # 'effnet-o':   ('checkpoints/effnet-v2rw-m-ordinal-dropout2-l2reg2-augs-full-epoch=22-val_loss=0.1580-val_acc=0.8278.ckpt',\n",
    "    #                EfficientNetV2OrdinalClassifier),\n",
    "    # 'resnet':     ('checkpoints/resnet-50-sv768-dropout-l2reg-augs-adjsmooth-part2-epoch=33-val_loss=0.8686-val_acc=0.8346.ckpt',\n",
    "    # 'resnet':     ('checkpoints/resnet-50-sv728dyn-rand_shrink-dropout-l2reg-augs-adjsmooth-train2-refine1-epoch=23-val_loss=0.9103-val_acc=0.8230.ckpt',\n",
    "    'resnet':     ('checkpoints/resnet-50-st477-sv768dyn-rand_shrink-dropout-l2reg-augs2-adjsmooth-train2-refine1-epoch=24-val_loss=0.8834-val_acc=0.8389.ckpt',\n",
    "                   ResNet50Classifier),\n",
    "    # 'resnet-n':   ('checkpoints/resnet-50-sv768-dropout-l2reg-augs-adjsmooth-part1-epoch=22-val_loss=0.6740-val_acc=0.8547.ckpt',\n",
    "    #                ResNet50Classifier),\n",
    "    # 'resnet-r':   ('checkpoints/resnet-50-reg-dropout-l2reg-augs-full-epoch=26-val_loss=0.3978-val_acc=0.7151.ckpt',\n",
    "    #                ResNet50Regressor),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d3b6968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing convnextâ€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9efc5bc3883486c88632f20ac271c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing effnetâ€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b6f392de0a40228c83ac120cb713c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing resnetâ€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a2d1b0c03b4d64824f35561adb63e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assume that test_dataloader does NOT shuffle, so order matches df_test\n",
    "\n",
    "# Loop each model\n",
    "for model_name, (ckpt_path, model_class) in models.items():\n",
    "    print(f'Processing {model_name}â€¦')\n",
    "\n",
    "    # 1) load & move to device\n",
    "    model = model_class.load_from_checkpoint(ckpt_path, strict=False)\n",
    "    model = model.to(device).eval()\n",
    "\n",
    "    # 2) collect raw outputs in a list\n",
    "    all_out = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(test_dataloader):\n",
    "            imgs = imgs.to(device)\n",
    "            with torch.amp.autocast(device.type):\n",
    "                out = model(imgs)\n",
    "            # out: Tensor of shape [B] or [B, D]\n",
    "            all_out.append(out.cpu())\n",
    "\n",
    "    # 3) concatenate and convert to numpy\n",
    "    all_out = torch.cat(all_out, dim=0).numpy()  # shape (N,) or (N, D)\n",
    "\n",
    "    # 4) turn into stacking columns\n",
    "    if all_out.ndim == 1:\n",
    "        # regressor â†’ one column\n",
    "        df_test[f'{model_name}_pred'] = all_out\n",
    "    else:\n",
    "        # multiâ€dim output â†’ one column per dim\n",
    "        D = all_out.shape[1]\n",
    "        for i in range(D):\n",
    "            df_test[f'{model_name}_{i}'] = all_out[:, i]\n",
    "\n",
    "    # cleanup\n",
    "    del model\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acebefe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.to_csv('df_test_inferred.csv', index=False)\n",
    "# df_test.to_csv('df_test_inferred-data1.csv', index=False)\n",
    "# df_test.to_csv('df_test_inferred-data2.csv', index=False)\n",
    "# df_test.to_csv('df_test_inferred-train2-data1.csv', index=False)\n",
    "# df_test.to_csv('df_test_inferred-train2-finetune1.csv', index=False)\n",
    "# df_test.to_csv('df_test_inferred-train2-shrunk1.csv', index=False)\n",
    "df_test.to_csv('df_test_inferred-train2-dyn1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd0ab79",
   "metadata": {},
   "source": [
    "==================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a144e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df_test21 = pd.read_csv('df_test_inferred-train2-data1.csv')\n",
    "# df_test21 = pd.read_csv('df_test_inferred-train2-finetune1.csv')\n",
    "# df_test21 = pd.read_csv('df_test_inferred-train2-shrunk1.csv')\n",
    "df_test21 = pd.read_csv('df_test_inferred-train2-dyn1.csv')\n",
    "\n",
    "# df_test1 = df_test[df_test['img_dir'].str.contains('aptos')]\n",
    "# df_test2 = df_test[df_test['img_dir'].str.contains('diabetic-retinopathy-detection')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30fda722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('diabetic-retinopathy-detection/test/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f4e5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2['group'] = df_test2['img_dir'].str.slice(start=46, stop=-5).str.split('_').str[0]\n",
    "df_test2.drop(columns=['img_dir'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b665c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in df_test2.columns if col not in ['group', 'label']]\n",
    "\n",
    "# Group by 'group' (pairs of rows)\n",
    "grouped = df_test2.groupby('group', sort=False)\n",
    "\n",
    "rows = []\n",
    "for patient_id, group in grouped:\n",
    "    left = group.iloc[0]\n",
    "    right = group.iloc[1]\n",
    "\n",
    "    # First row: left is the focus (X), right is the other (O)\n",
    "    row_1 = {'group': patient_id}\n",
    "    for col in feature_cols:\n",
    "        row_1[f'{col}_X'] = left[col]\n",
    "        row_1[f'{col}_O'] = right[col]\n",
    "    rows.append(row_1)\n",
    "\n",
    "    # Second row: right is the focus (X), left is the other (O)\n",
    "    row_2 = {'group': patient_id}\n",
    "    for col in feature_cols:\n",
    "        row_2[f'{col}_X'] = right[col]\n",
    "        row_2[f'{col}_O'] = left[col]\n",
    "    rows.append(row_2)\n",
    "\n",
    "# Final DataFrame\n",
    "df_test2_paired = pd.DataFrame(rows)\n",
    "df_test2_paired.drop(columns=['group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ebad80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "stacking_models_dirs = [f'stacking_models/stack-cb_gpu-train2-dyn1-fold{i}.pkl' for i in range(1,5+1)]\n",
    "stacking_models = [joblib.load(p) for p in stacking_models_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f4ddd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convnext_0',\n",
       " 'convnext_1',\n",
       " 'convnext_2',\n",
       " 'convnext_3',\n",
       " 'convnext_4',\n",
       " 'effnet_0',\n",
       " 'effnet_1',\n",
       " 'effnet_2',\n",
       " 'effnet_3',\n",
       " 'effnet_4']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_models[0].feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f405dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from tabpfn import TabPFNRegressor\n",
    "\n",
    "stacking_models_dirs = [f'stacking_models/stack-tabpfn-train2-finetune1-fold{i}.pkl' for i in range(1,5+1)]\n",
    "stacking_models = [joblib.load(p) for p in stacking_models_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4465c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preds = [model.predict(df_test2_paired) for model in stacking_models]\n",
    "# # preds = [model.predict(df_test2.drop(columns=['img_dir'])) for model in stacking_models]\n",
    "# preds = [model.predict(df_test2_paired) for model in stacking_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80fa9434",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [model.predict(df_test21.drop(columns=['img_dir'])) for model in stacking_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ab92d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8210509 , 2.80315379, 2.71027262, ..., 2.17839626, 3.23544422,\n",
       "       1.92815434])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d14c305e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.64177996, 2.99300709, 2.53380339, ..., 2.14300888, 3.30841184,\n",
       "       1.68540037])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c14232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_classes = 5\n",
    "\n",
    "preds_mean = np.mean(preds, axis=0)\n",
    "preds_mean_discrete = np.clip(np.rint(preds_mean), 0, num_classes - 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f886a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_convnext_r_discrete = np.clip(np.rint(df_test['convnext-r_pred'].values), 0, num_classes - 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fea8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1) Select only the convnext probability columns\n",
    "# cols = [f'convnext_{i}' for i in range(5)]\n",
    "# probs = df_test[cols].values  # shape (n_samples, 5)\n",
    "\n",
    "# # 2) Argmax along axis=1\n",
    "# preds_convnext_discrete = np.argmax(probs, axis=1)  # array of ints in [0..4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba1f84f",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9ed4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ss1 = pd.read_csv('aptos2019-blindness-detection/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88fdd6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('aptos2019-blindness-detection/test_images/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c3e514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit1 = pd.DataFrame()\n",
    "# df_submit1['id_code'] = df_test['img_dir'].str.slice(start=52, stop=-4)\n",
    "df_submit1['id_code'] = df_test21['img_dir'].str.slice(start=52, stop=-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5e5ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit1['diagnosis'] = preds_mean_discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ad4603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit1.to_csv('aptos2019-blindness-detection/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc2db07",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e08e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ss2 = pd.read_csv('diabetic-retinopathy-detection/sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acc789f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit2 = pd.DataFrame()\n",
    "# df_submit2['img_dir'] = df_test[df_test['img_dir'].str\\\n",
    "#                                 .contains('diabetic-retinopathy-detection')]['img_dir']\n",
    "df_submit2['img_dir'] = pd.read_csv('df_test2.csv')['img_dir']\n",
    "df_submit2['image'] = df_submit2['img_dir'].str.slice(start=46, stop=-5)\n",
    "df_submit2.drop(columns=['img_dir'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a34b8980",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit2['level'] = preds_mean_discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f952434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit2.to_csv('diabetic-retinopathy-detection/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2b353a",
   "metadata": {},
   "source": [
    "============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8beb219e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('aptos2019-blindness-detection/test_images/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8bfa31c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit1 = df_test[df_test['img_dir'].str.contains('aptos2019-blindness-detection')][['img_dir', 'level']]\n",
    "df_submit1['img_dir'] = df_submit1['img_dir'].str.slice(start=52)\n",
    "df_submit1['img_dir'] = df_submit1['img_dir'].str.slice(stop=-4)\n",
    "df_submit1 = df_submit1.rename(columns={'img_dir': 'id_code', 'level': 'diagnosis'})\n",
    "df_submit1.to_csv('aptos2019-blindness-detection/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a44dd",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e8331a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('diabetic-retinopathy-detection/test/processed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac46d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit2 = df_test[df_test['img_dir'].str.contains('diabetic-retinopathy-detection')][['img_dir', 'level']]\n",
    "df_submit2['img_dir'] = df_submit2['img_dir'].str.slice(start=46)\n",
    "df_submit2['img_dir'] = df_submit2['img_dir'].str.slice(stop=-5)\n",
    "df_submit2 = df_submit2.rename(columns={'img_dir': 'image'})\n",
    "df_submit2.to_csv('diabetic-retinopathy-detection/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7375e5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-dl-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
